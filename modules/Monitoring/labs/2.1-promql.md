
# Lab: PromQL and SLO Dashboards

## Overview

In Lab 1.3, you built a logging stack with Loki, Promtail, and Grafana. Now you'll add **Prometheus** to collect metrics from your FastAPI application and build a dashboard focused on **Service Level Objectives (SLOs)**.

By the end of this lab, you'll have:
- Prometheus scraping metrics from your API
- A Grafana dashboard with logs, availability, latency, and error rate panels
- Hands-on experience with PromQL aggregation patterns

---

## Part 1: Extend the Docker Compose Stack

We'll build on the stack from Lab 1.3. Navigate to your existing directory or create a new one:

```bash
cd ~/loki-lab
```

### Update docker-compose.yml

Replace your existing `docker-compose.yml` with the following. Notice we're adding **Prometheus** and updating the datasources:

```yaml
services:
  api:
    build: ./api
    container_name: telemetry-api
    ports:
      - "8000:8000"
    networks:
      - monitoring
    labels:
      - "app=telemetry-api"

  prometheus:
    image: prom/prometheus:v2.48.0
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
    networks:
      - monitoring

  promtail:
    image: grafana/promtail:3.2.1
    container_name: promtail
    command: ["-config.file=/etc/promtail/promtail-config.yaml"]
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./promtail-config.yaml:/etc/promtail/promtail-config.yaml
    networks:
      - monitoring
    depends_on:
      - loki

  loki:
    image: grafana/loki:2.9.0
    container_name: loki
    ports:
      - "3100:3100"
    networks:
      - monitoring

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    volumes:
      - ./datasources.yaml:/etc/grafana/provisioning/datasources/datasources.yaml
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    networks:
      - monitoring
    depends_on:
      - loki
      - prometheus
    labels:
      - "app=grafana"

networks:
  monitoring:
    driver: bridge
```

### Create prometheus.yml

This tells Prometheus where to scrape metrics:

```yaml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'fastapi'
    static_configs:
      - targets: ['api:8000']
    metrics_path: /metrics
```

### Update datasources.yaml

Add Prometheus as a datasource alongside Loki:

```yaml
apiVersion: 1

datasources:
  - name: Prometheus
    type: prometheus
    access: proxy
    url: http://prometheus:9090
    isDefault: true

  - name: Loki
    type: loki
    access: proxy
    url: http://loki:3100
```

### Start the Stack

```bash
docker compose up -d --build
```

Verify all five containers are running:

```bash
docker ps
```

You should see: `telemetry-api`, `prometheus`, `promtail`, `loki`, and `grafana`.

---

## Part 2: Explore FastAPI Metrics

The `prometheus-fastapi-instrumentator` library automatically exposes metrics at `/metrics`. Let's see what's available.

### View Raw Metrics

```bash
curl http://localhost:8000/metrics
```

You'll see output like:

```
# HELP http_requests_total Total number of requests by method, status and handler.
# TYPE http_requests_total counter
http_requests_total{handler="/",method="GET",status="2xx"} 5.0
http_requests_total{handler="/items/{item_id}",method="GET",status="2xx"} 12.0
http_requests_total{handler="/items/{item_id}",method="GET",status="4xx"} 3.0

# HELP http_request_duration_seconds Duration of HTTP requests in seconds
# TYPE http_request_duration_seconds histogram
http_request_duration_seconds_bucket{handler="/",method="GET",le="0.1"} 5.0
http_request_duration_seconds_bucket{handler="/",method="GET",le="0.5"} 5.0
...
```

### Key Metrics from FastAPI Instrumentator

| Metric | Type | Description |
|--------|------|-------------|
| `http_requests_total` | Counter | Total requests by handler, method, status |
| `http_request_duration_seconds` | Histogram | Request latency distribution |
| `http_requests_in_progress` | Gauge | Currently active requests |

### Generate Traffic

Before building dashboards, generate some realistic traffic:

```bash
# Mix of successful and failing requests
for i in {1..50}; do
  curl -s http://localhost:8000/ > /dev/null
  curl -s http://localhost:8000/items/1 > /dev/null
  curl -s http://localhost:8000/items/999 > /dev/null  # 404
  curl -s -X POST http://localhost:8000/items/1/process > /dev/null  # may fail
  sleep 0.5
done
```

### Verify Prometheus is Scraping

1. Open Prometheus: http://localhost:9090
2. Go to **Status** → **Targets**
3. You should see `fastapi` target in "UP" state

---

## Part 3: PromQL Fundamentals

Before building the dashboard, let's understand the queries we'll use.

### Basic Queries in Prometheus UI

Go to http://localhost:9090 and try these queries:

**Total requests:**
```promql
http_requests_total
```

**Requests to a specific endpoint:**
```promql
http_requests_total{handler="/items/{item_id}"}
```

**Only successful requests:**
```promql
http_requests_total{status="2xx"}
```

### Rate: Measuring Request Frequency

Raw counters always go up. To see "requests per second," use `rate()`:

```promql
rate(http_requests_total[5m])
```

This shows the per-second rate over the last 5 minutes.

### Aggregation with `sum by`

When you have multiple label values, you can aggregate:

**Total request rate across all endpoints:**
```promql
sum(rate(http_requests_total[5m]))
```

**Request rate broken down by handler:**
```promql
sum by (handler) (rate(http_requests_total[5m]))
```

**Request rate by status category:**
```promql
sum by (status) (rate(http_requests_total[5m]))
```

---

## Part 4: SLO-Focused PromQL Patterns

SLOs (Service Level Objectives) typically focus on:
- **Availability**: Percentage of successful requests
- **Latency**: Response time percentiles

### Error Rate by Handler

This query calculates the error rate (5xx responses) for each endpoint:

```promql
sum by (handler) (rate(http_requests_total{status="5xx"}[5m]))
/
sum by (handler) (rate(http_requests_total[5m]))
```

**How it works:**
1. Numerator: Rate of 5xx errors per handler
2. Denominator: Rate of all requests per handler
3. Result: Percentage of requests that failed (0.0 to 1.0)

### Availability by Handler

Availability is the inverse of error rate:

```promql
1 - (
  sum by (handler) (rate(http_requests_total{status="5xx"}[5m]))
  /
  sum by (handler) (rate(http_requests_total[5m]))
)
```

### Latency Percentiles

The `http_request_duration_seconds` histogram lets you calculate percentiles:

**95th percentile latency by handler:**
```promql
histogram_quantile(0.95, 
  sum by (handler, le) (rate(http_request_duration_seconds_bucket[5m]))
)
```

**99th percentile overall:**
```promql
histogram_quantile(0.99, 
  sum by (le) (rate(http_request_duration_seconds_bucket[5m]))
)
```

---

## Part 5: Build the SLO Dashboard

Now let's create a dashboard in Grafana with 5 panels covering logs, availability, and latency.

### Access Grafana

1. Open http://localhost:3000
2. Login with `admin` / `admin`
3. Click **Dashboards** → **New** → **New Dashboard**

---

### Panel 1: Application Logs (Loki)

This panel shows FastAPI logs with a search box for filtering.

1. Click **Add visualization**
2. Select **Loki** as the data source
3. Switch to **Code** mode and enter:

```logql
{container="telemetry-api"} |= `$searchText`
```

4. Configure the panel:
   - **Visualization**: Logs
   - **Title**: Application Logs

5. Add a dashboard variable for the search box:
   - Click the **gear icon** (Dashboard settings) → **Variables** → **Add variable**
   - **Name**: `searchText`
   - **Type**: Text box
   - **Label**: Search Logs
   - Click **Apply**

6. Go back to the dashboard and update the panel query to use the variable:

```logql
{container="telemetry-api"} |= `$searchText`
```

Now you have a text box at the top of the dashboard to filter logs!

---

### Panel 2: Request Rate by Handler

1. Click **Add** → **Visualization**
2. Select **Prometheus** as the data source
3. Enter the query:

```promql
sum by (handler) (rate(http_requests_total[5m]))
```

4. Configure:
   - **Visualization**: Time series
   - **Title**: Request Rate by Endpoint
   - **Legend**: `{{handler}}`

---

### Panel 3: Availability by Handler

1. Add a new visualization with **Prometheus**
2. Enter the query:

```promql
(1 - (
  sum by (handler) (rate(http_requests_total{status="5xx"}[5m]))
  /
  sum by (handler) (rate(http_requests_total[5m]))
)) * 100
```

3. Configure:
   - **Visualization**: Stat or Gauge
   - **Title**: Availability % by Endpoint
   - **Unit**: Percent (0-100)
   - **Thresholds**: 
     - Green: > 99
     - Yellow: > 95
     - Red: < 95

---

### Panel 4: Error Rate by Handler

1. Add a new visualization with **Prometheus**
2. Enter the query:

```promql
sum by (handler) (rate(http_requests_total{status=~"4xx|5xx"}[5m]))
/
sum by (handler) (rate(http_requests_total[5m]))
* 100
```

3. Configure:
   - **Visualization**: Time series
   - **Title**: Error Rate % by Endpoint
   - **Legend**: `{{handler}}`
   - **Unit**: Percent (0-100)

---

### Panel 5: P95 Latency by Handler

1. Add a new visualization with **Prometheus**
2. Enter the query:

```promql
histogram_quantile(0.95, 
  sum by (handler, le) (rate(http_request_duration_seconds_bucket[5m]))
)
```

3. Configure:
   - **Visualization**: Time series
   - **Title**: P95 Latency by Endpoint
   - **Legend**: `{{handler}}`
   - **Unit**: seconds (s)

---

### Arrange and Save

1. Drag panels to arrange them logically:
   - Top row: Logs panel (full width)
   - Second row: Request Rate, Availability
   - Third row: Error Rate, P95 Latency

2. Click **Save dashboard** (disk icon)
3. Name it: `FastAPI SLO Dashboard`

---

## Part 6: Generate Load and Observe

Let's generate varied traffic to see the dashboard in action:

```bash
# Sustained traffic with mixed results
while true; do
  # Normal requests
  curl -s http://localhost:8000/ > /dev/null
  curl -s http://localhost:8000/items/1 > /dev/null
  curl -s http://localhost:8000/items/2 > /dev/null
  
  # Some 404s
  curl -s http://localhost:8000/items/999 > /dev/null
  
  # Processing endpoint (has random failures and latency)
  curl -s -X POST http://localhost:8000/items/1/process > /dev/null
  curl -s -X POST http://localhost:8000/items/2/process > /dev/null
  
  sleep 1
done
```

Run this for a few minutes while watching your dashboard. You should see:
- Logs streaming in real-time
- Request rates for different endpoints
- Availability dipping when the `/process` endpoint fails
- Latency spikes for the slow `/process` endpoint

Use the **Search Logs** text box to filter for specific terms like "error" or "process".

**Press Ctrl+C to stop the traffic generator when done.**

---

## Part 7: Understanding the `sum by` Pattern

The `sum by` pattern is fundamental to PromQL. Let's break it down:

### Without Aggregation

```promql
rate(http_requests_total[5m])
```

Returns one time series per unique label combination:
- `{handler="/", method="GET", status="2xx"}`
- `{handler="/items/{item_id}", method="GET", status="2xx"}`
- `{handler="/items/{item_id}", method="GET", status="4xx"}`
- ... many more

### With `sum by (handler)`

```promql
sum by (handler) (rate(http_requests_total[5m]))
```

Groups all label combinations by `handler` and sums them:
- `{handler="/"}` → total rate for root endpoint
- `{handler="/items/{item_id}"}` → total rate for items endpoint

### Ratio Queries

When calculating ratios like error rate:

```promql
sum by (handler) (rate(http_requests_total{status="5xx"}[5m]))
/
sum by (handler) (rate(http_requests_total[5m]))
```

Both sides must have the same `by` clause to match up correctly. Prometheus divides matching label sets:
- `{handler="/"}` errors / `{handler="/"}` total
- `{handler="/items/{item_id}"}` errors / `{handler="/items/{item_id}"}` total

---

## Cleanup

When you're done:

```bash
docker compose down
```

---

## Summary

| Concept | What You Learned |
|---------|------------------|
| **Prometheus** | Scrapes and stores time-series metrics |
| **rate()** | Converts counters to per-second rates |
| **sum by** | Aggregates metrics by specific labels |
| **histogram_quantile** | Calculates percentiles from histograms |
| **SLO Metrics** | Availability, latency, error rate |

### PromQL Quick Reference

| Pattern | Use Case |
|---------|----------|
| `rate(metric[5m])` | Per-second rate over 5 minutes |
| `sum by (label) (...)` | Aggregate by label |
| `sum(rate(...{filter})) / sum(rate(...))` | Calculate percentage |
| `histogram_quantile(0.95, sum by (le) (...))` | P95 latency |

### Dashboard Panels Created

| Panel | Data Source | Purpose |
|-------|-------------|---------|
| Application Logs | Loki | Real-time log viewer with search |
| Request Rate | Prometheus | Traffic volume per endpoint |
| Availability % | Prometheus | SLO: success rate per endpoint |
| Error Rate % | Prometheus | Track failures by endpoint |
| P95 Latency | Prometheus | SLO: response time per endpoint |

---

## Next Steps

In the next lab, you'll explore more advanced LogQL queries to parse and analyze structured log data.

